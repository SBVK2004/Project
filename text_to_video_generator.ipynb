import torch
from diffusers import DiffusionPipeline
from diffusers.utils import export_to_video
import os
import re

torch.set_grad_enabled(False)

model_id = "damo-vilab/text-to-video-ms-1.7b"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

try:
    pipeline = DiffusionPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16 if device.type == "cuda" else torch.float32
    )
    pipeline = pipeline.to(device)
    print("ModelScope Text-to-Video pipeline loaded successfully.")
except Exception as e:
    print(f"Error loading pipeline: {e}")
    print("Make sure you have downloaded the model weights and have enough memory.")
    print("You might need to login to Hugging Face if it's a gated model: huggingface-cli login")
    exit()

prompt = input("Enter your text prompt for video generation: ")

fps = 8
n_seconds = 4
num_frames = fps * n_seconds

print(f"\nGenerating a {n_seconds}-second video for prompt: '{prompt}'...")

try:
    video_frames = pipeline(
        prompt,
        num_frames=num_frames,
    ).frames[0]

    sanitized_prompt = re.sub(r'[^\w\s-]', '', prompt)
    sanitized_prompt = sanitized_prompt.replace(' ', '_').lower()
    max_filename_length = 50
    if len(sanitized_prompt) > max_filename_length:
        sanitized_prompt = sanitized_prompt[:max_filename_length]

    output_filename = f"{sanitized_prompt}.mp4"

    video_path = export_to_video(video_frames, output_video_path=output_filename, fps=fps)
    print(f"Video saved to: {video_path}")

except Exception as e:
    print(f"Error generating video: {e}")
finally:
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("Cleared CUDA cache.")